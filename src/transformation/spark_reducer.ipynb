{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = spark.read.csv('../../data/raw/data2.csv',header=True, inferSchema=True)\n",
    "data2= spark.read.csv('../../data/raw/data3.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## flatten and grouping the first data\n",
    "column_df=data1.select('skills')\n",
    "rdd = column_df.rdd.map(lambda row: row[0])\n",
    "splitted_rdd = rdd.flatMap(lambda line : line.split('Â·'))\n",
    "word_pairs1 = splitted_rdd.map(lambda word : (word,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2= data2.groupBy(\"Skill\").agg(sum(\"Count\").alias(\"Total_count\"))\n",
    "word_pairs2 = df2.rdd.map(lambda row: f\"({row['Skill']}: {row['Total_count']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Experienced ', 1), (' 1 - 3 Yrs of Exp ', 1), (' IT/Software Development ', 1), (' Computer Science ', 1), (' Software Development ', 1), (' Python', 1), ('Entry Level ', 1), (' 0 - 5 Yrs of Exp ', 1), (' IT/Software Development ', 1), (' Education/Teaching ', 1), (' Training/Instructor ', 1), (' Computer Science ', 1), (' Information Technology (IT) ', 1), (' Python ', 1), (' Instructor', 1), ('Experienced ', 1), (' 5 - 8 Yrs of Exp ', 1), (' IT/Software Development ', 1), (' Engineering - Telecom/Technology ', 1), (' React ', 1), (' Django ', 1), (' Full Stack Development ', 1), (' Information Technology (IT) ', 1), (' Computer Science ', 1), (' RESTful API ', 1), (' Microservice Architecture ', 1), (' Database Systems', 1), ('Entry Level ', 1), (' 2+ Yrs of Exp ', 1), (' IT/Software Development ', 1), (' Engineering - Telecom/Technology ', 1), (' Python ', 1), (' Django ', 1), (' Flask ', 1), (' Python Scripting ', 1), (' Web Scraping ', 1), (' WWeb Scraping ', 1), (' CI ', 1), (' Computer Science', 1), ('Entry Level ', 1), (' 1 - 3 Yrs of Exp ', 1), (' Business Development ', 1), (' IT/Software Development ', 1), (' Engineering - Telecom/Technology ', 1), (' Python ', 1), (' MySQL ', 1), (' JavaScript ', 1), (' React ', 1), (' Angular ', 1), (' RESTful ', 1)]\n"
     ]
    }
   ],
   "source": [
    "union_rdd= word_pairs1.union(word_pairs2)\n",
    "print(union_rdd.take(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_rdd = union_rdd.map(lambda x: (x[0].strip(), x[1]))\n",
    "\n",
    "word_count= trimmed_rdd.reduceByKey(lambda a ,b : a+b)\n",
    "word_count.coalesce(1).saveAsTextFile('../../data/transformed/data_final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
